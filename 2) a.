import numpy as np
import random
class Alice:
    def __init__(self):
        self.past_play_styles = np.array([1,1])  
        self.results = np.array([1,0])           
        self.opp_play_styles = np.array([1,1])  
        self.points = 1

    def play_move(self):
        """
        Decide Alice's play style for the current round. Implement your strategy for 3a here.
        
        Returns: 
            0 : attack
            1 : balanced
            2 : defence

        """
        #attack
        a=(1/3)*(((len(self.results)-self.points)/len(self.results))+ 7/10 + 5/11)
        #balance
        b=(1/3)*(3/10 + 1/3 + (1/2)*(1/3) + 3/10 + (1/2)*(1/2))
        #defend
        c=(1/3)*(6/11 + 1/5 + (1/2)*(1/2) + 1/10 + (4/5)*(1/2))
        #print(c)
        if(a==max(a,b,c)):
            return 0
        elif(b==max(a,b,c)):
            return 1
        else:
            return 2

        pass
        
    
    def observe_result(self, own_style, opp_style, result):
        """
        Update Alice's knowledge after each round based on the observed results.
        
        Returns:
            None
        """
        self.past_play_styles=np.append(self.past_play_styles, own_style)
        self.results=np.append(self.results,result)
        self.opp_play_styles=np.append(self.opp_play_styles, opp_style)
        self.points += result
        pass

class Bob:
    def __init__(self):
        # Initialize numpy arrays to store Bob's past play styles, results, and opponent's play styles
        self.past_play_styles = np.array([1,1]) 
        self.results = np.array([0,1])          
        self.opp_play_styles = np.array([1,1])   
        self.points = 1

    def play_move(self):
        """
        Decide Bob's play style for the current round.

        Returns:
            Returns: 
            0 : attack
            1 : balanced
            2 : defence
        
        """
        move = np.random.choice([0, 1, 2])
        return move
        
    
    def observe_result(self, own_style, opp_style, result):
        """
        Update Bob's knowledge after each round based on the observed results.
        
        Returns:
            None
        """
        self.past_play_styles=np.append(self.past_play_styles, own_style)
        self.results=np.append(self.results,result)
        self.opp_play_styles=np.append(self.opp_play_styles, opp_style)
        self.points += result
 

def simulate_round(alice, bob, payoff_matrix):
    """
    Simulates a single round of the game between Alice and Bob.
    
    Returns:
        None
    """
    payoff_matrix[0][0]=(bob.points/(bob.points+alice.points),0,alice.points/(alice.points+bob.points))
    alice_move = alice.play_move()
    bob_move = bob.play_move()
    arr=[1,0.5,0]
    result=random.choices(arr, weights=(payoff_matrix[alice_move][bob_move][0], payoff_matrix[alice_move][bob_move][1], payoff_matrix[alice_move][bob_move][2]), k=1)
    alice.observe_result(alice_move, bob_move, result[0])
    bob.observe_result(bob_move, alice_move, 1 - result[0])
    pass
    


def monte_carlo(num_rounds):
    """
    Runs a Monte Carlo simulation of the game for a specified number of rounds.
    
    Returns:
        None
    """
    alice= Alice()
    bob=Bob()
    payoff_matrix = np.array([
        [(bob.points/(bob.points+alice.points),0,alice.points/(alice.points+bob.points)), (0.7,0,0.3), (5/11,0,6/11)],  
        [(0.3, 0, 0.7), (1/3,1/3,1/3), (0.3,0.5,0.2)], 
        [(6/11,0,5/11), (0.2,0.5,0.3), (0.1,0.8,0.1)]   
    ])
    
    for _ in range(num_rounds-2):
        simulate_round(alice, bob, payoff_matrix)
    return(alice.points/num_rounds)
    pass
    
 

# Run Monte Carlo simulation with a specified number of rounds
if __name__ == "__main__":
    monte_carlo(num_rounds=100000)
    
